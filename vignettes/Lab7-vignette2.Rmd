---
title: "Lab7-Vignette2"
author: "Oscar Petterson and Vuong Tran"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Lab7-Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---


## 1

```{r}
library(caret)
library(mlbench)
library(Lab7)
data("BostonHousing")
```

We have data about 506 properties in Boston from 1970. 14 variables are included. We want to predict the crime rate (per capita), using the other 13 variables.

```{r}
head(BostonHousing)
```

We divide the dataset into 70 % training and 30 % test data.

```{r}
set.seed(1337)
inTraining <- caret::createDataPartition(BostonHousing$crim, p = .7, list = FALSE)
training <- BostonHousing[ inTraining,]
testing  <- BostonHousing[-inTraining,]
fitControl <- caret::trainControl(## 10-fold CV
  method = "repeatedcv",
  number = 10,
  ## repeated ten times
  repeats = 10)
```

However, for future analysis, we will standardize all predictors. The factor variable chas contains only two classes, so  no dummies are needed and we may convert it into a usual numeric variable.

```{r}
BostonHousing$chas <- as.numeric(BostonHousing$chas) - 1
BostonHousing <- scale(BostonHousing)
```


## 2
We use the caret package and its train function to fit a linear regression model on the training set:

```{r}
set.seed(1337)
lmFit <- caret::train(crim ~ ., data = training,
                      method = "lm",
                      trControl = fitControl
)
lmFit


```

Now, we try finding a linear regression model using forward selection, on the same training data as before:
  
```{r}
lmGrid <-  expand.grid(nvmax=1:(ncol(training)-1))
set.seed(1337)
fsFit <- caret::train(crim ~ ., data = training,
                      method = "leapForward",
                      trControl = fitControl,
                      tuneGrid=lmGrid
)

fsFit
```

## 3
When comparing our two different methods lm and leapFoward, the result show that using only seven predictor is not better than using all 13 of them with respect to the RMSE value. We can't compare the Rsquared values since lm and leapFowards methods give us two different best models with different amount of predictors.

## 4-5

We try the caret train function with our function ridgereg as methods with lambda, variating from 0 to 500 and see that the best values are when lambda is 500. This makes us try higher values. We do several new runs, and eventually noticed that the best values was when lambda was equal to 828.4.
The differences can be seen down here:
  
```{r}

lmRig<-list(type=c("Regression","Classification"),
            library="Lab7",
            loop=NULL)

lmRig$parameters<-data.frame(parameter="lambda",
                             class="numeric",
                             label="Lambda")

# 
# Fit<-function(formula,data,lambda,param,lev,last,classProbs,...){
# 
#   
#   Lab7::ridgereg( formula=formula,data=data,lambda=param$lambda)
# }


Fit<-function(x,y,lambda,param,lev,last,classProbs,...){
  
  dat <- as.data.frame(x)
  dat$response <- y
  
  formula <- "response ~ "
  
  formula <- paste(formula, names(dat)[1], sep="")
  
  if(ncol(x) > 1){
    for(i in 2:ncol(x)){
      
      formula <- paste(formula, " + ", names(dat)[i], sep="")
      
    }
  }
  
  formula <- as.formula(formula)
  Lab7::ridgereg( formula = formula, data=dat,lambda=param$lambda)
}

lmRig$fit<-Fit

lmRig$predict<-function (modelFit, newdata,preProc=NULL, submodels = NULL) 
{
  predict(modelFit, newdata)
}

lmRig$prob<- list(NULL)

lmRig$sort<-function (x) x[order(-x$lambda), ]

lmRig$label<-"Ridgeregression"

lmRig$grid<-function(x,y,len=NULL, search="grid"){
  # data.frame(lambda=seq(from=0, to=500, by=10))
  # data.frame(lambda=seq(from=500, to=1000, by=25))
  # data.frame(lambda=seq(from=750, to=850, by=10))
  # data.frame(lambda=seq(from=820, to=840, by=1))
  # data.frame(lambda=seq(from=825, to=830, by=0.1))
  data.frame(lambda=c(0, 1, 2, 500, 828, 828.4, 830, 1000))
}

set.seed(1337)
rrFit1 <- caret::train(crim ~ ., data = training,
                       method = lmRig,
                       trControl = fitControl
)
rrFit1
```

## 6
When our tuning parameter lambda is zero, ridge regression is equal to OLS and as we can see, the Root Mean Squared Error is much lower for the best tuning value. Our Rigdgereg with best tuning paramether (lambda = 828.4) is also better than the best model from the leapForward method (linear regression with seven explanatory variables).

We try the best value (lambda = 828.4) on the data:

```{r}
best_model <- ridgereg(crim ~ zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + b + lstat + medv, data = as.data.frame(BostonHousing), lambda = 828.4)
print(best_model)
qqnorm(best_model$res)
qqline(best_model$res)
plot(best_model$res, type="o", pch=20, cex=0.5)
```

But the residuals of the best ridgereg model aren't very good.